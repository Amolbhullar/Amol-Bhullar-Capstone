{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f59ed07",
   "metadata": {},
   "source": [
    "After the Modeling of the Jupyter Notebook called 'Models with TF-IDF Vectorization.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443fc0b",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    " # Table of Contents  \n",
    "1. [Introduction](#1)\n",
    "    1. [Loading Packages](#2) \n",
    "    1. [Loading Dataset](#3) \n",
    "1. [Creating Dictionaries](#5) \n",
    "1. [Hugging Face](#7)     \n",
    "    1. [The Dataset](#8) \n",
    "    1. [The Tokenizer](#10) \n",
    "        1. [Model Setup for Text Classification](#11)\n",
    "        1. [distilbert-base-uncased Model Evaluation](#12)\n",
    "        1. [Transfer Learning Pipeline](#16)\n",
    "    1. [Running the Model](#13) \n",
    "        1. [Running the Model](#14)\n",
    "        1. [Model Predictions](#15) \n",
    "1. [Conclusion](#17)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232e935",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d9a53",
   "metadata": {},
   "source": [
    "For this model we will be using the Hugging Face model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2faa4",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "### 1a. Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bbc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers==0.11.1\n",
    "!pip install transformers scipy ftfy accelerate datasets s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import TextClassificationPipeline\n",
    "from datasets import load_dataset\n",
    "from transformers import XLMRobertaXLConfig, XLMRobertaXLModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa8cc4",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "### 1a. Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3aed3",
   "metadata": {},
   "source": [
    "Loading the dataset from the EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa057b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gluten_free = pd.read_csv(\"Capstone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "gluten_free.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430de402",
   "metadata": {},
   "outputs": [],
   "source": [
    "gluten_free['gluten_free?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d253959",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50d665",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "# Creating Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out target categories need to be encoded as integers, but we'll want to reverse this\n",
    "# encoding back to the original categorical strings later, so we need forward and reverse lookups.\n",
    "id2label = {i:cat for i,cat in enumerate(set(gluten_free[\"gluten_free?\"]))}\n",
    "label2id = {v:k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d58a6",
   "metadata": {},
   "source": [
    "<b>Two Dictionaries<b>\n",
    "    \n",
    "1. id2label: This dictionary maps integer labels to their original categorical values.\n",
    "2. label2id: This dictionary maps original categorical values to their corresponding integer labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde493ee",
   "metadata": {},
   "source": [
    "#### Lets start with spliting the data:\n",
    "\n",
    "1. Takes the two columns from the gluten_free dataset, \"gluten_free?\" and \"description.\"\n",
    "2. Renames these columns to \"label\" and \"text\"\n",
    "3. Using the dictionaries from above it converts the values in the \"label\" column (which are categorical) into integer labels.\n",
    "4. Generates a random test/train split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out columns of interest and do a manual test_train split based on random integer assignment\n",
    "simplified = gluten_free[[\"gluten_free?\",\"description\"]].copy()\n",
    "simplified.columns = [\"label\",\"text\"]\n",
    "simplified.loc[:,\"label\"] = list(label2id[lab] for lab in simplified[\"label\"])\n",
    "test_flag = np.random.randint(0,high=10,size=gluten_free.shape[0])\n",
    "simplified.loc[:,'test'] = test_flag > 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5e318",
   "metadata": {},
   "source": [
    "#### Lets split according to test and train\n",
    "\n",
    "The train dataset contains 50,000 samples from each category for training.\n",
    "The test dataset contains 100,000 samples for evaluation during tuning, randomly selected from the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 50,000 of each category for training\n",
    "train = simplified[~simplified.test].groupby('label',group_keys=False).apply(lambda x: x.sample(50000))\n",
    "\n",
    "# select 100000 of each cagegory for test evaluation during tuning\n",
    "test = simplified[simplified.test].sample(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c0071",
   "metadata": {},
   "source": [
    "Let's see the size of the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5268c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of test set: {test.shape}')\n",
    "print(f'Shape of train set: {train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7ffe2",
   "metadata": {},
   "source": [
    "Lets the test and train as CSV files to be processed by the hugging face data pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5192c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as CSV files to be processed by the hugging face data pipelines\n",
    "train.reset_index(drop=True).to_csv(\"gluten_free_train.csv\")\n",
    "test.reset_index(drop=True).to_csv(\"gluten_free_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858d721",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c77cf0",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> \n",
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d3908",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dcf04b",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> \n",
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cae06",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f8c26",
   "metadata": {},
   "source": [
    "Let's load the datasets we created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac431b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load as hugging face dataset\n",
    "dataset = load_dataset('csv', data_files={'train': 'gluten_free_train.csv', 'test': 'gluten_free_test.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc08cd",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755926e",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> \n",
    "### The Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54f470",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05d0df",
   "metadata": {},
   "source": [
    "For this model we will use the distilbert-base-uncased tokenizer from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90202832",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load a tokenizer from our target language model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "# pro forma hugging face text processing setup\n",
    "tokenized_data = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c9812",
   "metadata": {},
   "source": [
    "1. Loading a Tokenizer:\n",
    "It loads a tokenizer from the Hugging Face model. It uses the \"distilbert-base-uncased\" tokenizer. Tokenizers are used to convert text data into tokens that can be fed into a language model.\n",
    "2. Preprocessing Function:\n",
    "It takes an input called examples, which is expected to have a key named \"text\" containing the text data.\n",
    "It tokenizes the text using the \"distilbert-base-uncased\" tokenizer, with padding=True to ensure all sequences have the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502b463",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a> \n",
    "##### Model Setup for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup for text classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69598b79",
   "metadata": {},
   "source": [
    "1. Loading a Pre-trained Model:\n",
    "It loads a pre-trained classification model  from the Hugging Face model. It uses the \"distilbert-base-uncased\" model.\n",
    "2. Specifying the Number of Labels:\n",
    "It uses the length of the label2id dictionary to determine the number of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1295c8f",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> \n",
    "##### distilbert-base-uncased Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f828e",
   "metadata": {},
   "source": [
    "Lets create a function which will evulate the model so we can compare it to the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7768f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# leverage sklearn metrics for runtime training evaluation\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred,average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred,average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred,average='micro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a892b",
   "metadata": {},
   "source": [
    "This funciton calcuates the accuracy, precision, recall and f1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44242f3f",
   "metadata": {},
   "source": [
    "<a id=\"16\"></a> \n",
    "##### Transfer Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f203b07",
   "metadata": {},
   "source": [
    "Lets complete the transfer learning pipeline by instantiating a TrainingArguments instance with specific parameters and creating a new Trainer that collects all components together: model, training_args, preprocessing pipeline, and evaluation funcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94792505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training parameter setup goes in a specific class instance\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gluten_free-classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    optim=\"adamw_torch\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False)\n",
    "\n",
    "# the trainier\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd6b4f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ca452",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a> \n",
    "### Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d16f22",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d790f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626aa83",
   "metadata": {},
   "source": [
    "<a id=\"14\"></a> \n",
    "##### Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464da1b",
   "metadata": {},
   "source": [
    "| Epoch | Training Loss | Validation Loss | Accuracy | Precision |Recall | F1 |\n",
    "| --- | --- | --- |--- | --- | --- |--- |\n",
    "| 1 | 0.407 | 0.403 | 0.817 | 0.817 | 0.817| 0.817|\n",
    "| 2 | 0.342 | 0.384 | 0.830 | 0.830 | 0.830| 0.830|\n",
    "| 3 | 0.292 | 0.350 | 0.849 | 0.849 | 0.849| 0.849|\n",
    "| 4 | 0.253 | 0.346 | 0.855 | 0.855 | 0.855| 0.855|\n",
    "| 2 | 0.226 | 0.375 | 0.850 | 0.850 | 0.850| 0.850|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39d61e",
   "metadata": {},
   "source": [
    "The table above shows the accuracy is increasing, and the training loss is decreasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d15f6",
   "metadata": {},
   "source": [
    "Lets save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f95077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"best_model.pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177fb5",
   "metadata": {},
   "source": [
    "<a id=\"15\"></a> \n",
    "##### Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8555a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions for the entire dataset\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=False, device='cuda')\n",
    "pipe([\"organic chocolate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5423c8b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a05ff",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a> \n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ad18c",
   "metadata": {},
   "source": [
    "##### Prevoius Insights\n",
    "The TF-IDF Vectorization is more accurate than CountVectorization.\n",
    "\n",
    "Overall, both the Logistic Regression model has a slightly better balance between precision and recall for both classes. Both the Decision Tree models have the higest accuracy and perform reasonably well but has lower precision and recall for class 0, therefore struggles with identifying non-gluten-free products. The Naive Bayes model performs well but has slightly lower accuracy and precision for class 0 compared to Logistic Regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc86200",
   "metadata": {},
   "source": [
    "| Model | Vectorization | Accuracy %|\n",
    "| --- | --- | --- |\n",
    "| Naive Bayes | TF-IDF | 0.7611 |\n",
    "| Logistic Regression | TF-IDF  | 0.7613 |\n",
    "| Decision Tree | TF-IDF | 0.7625 |\n",
    "| Naive Bayes | CountVectorization | 0.7416 |\n",
    "| Logistic Regression | CountVectorization  | 0.7614 |\n",
    "| Decision Tree | CountVectorization | 0.7628 |\n",
    "\n",
    "\n",
    "#### distilbert-base-uncased Model\n",
    "| Epoch | Training Loss | Validation Loss | Accuracy | Precision |Recall | F1 |\n",
    "| --- | --- | --- |--- | --- | --- |--- |\n",
    "| 1 | 0.407 | 0.403 | 0.817 | 0.817 | 0.817| 0.817|\n",
    "| 2 | 0.342 | 0.384 | 0.830 | 0.830 | 0.830| 0.830|\n",
    "| 3 | 0.292 | 0.350 | 0.849 | 0.849 | 0.849| 0.849|\n",
    "| 4 | 0.253 | 0.346 | 0.855 | 0.855 | 0.855| 0.855|\n",
    "| 2 | 0.226 | 0.375 | 0.850 | 0.850 | 0.850| 0.850|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feacf08",
   "metadata": {},
   "source": [
    "##### After distilbert-base-uncased Modeling\n",
    "\n",
    "We can say with certanity distilbert-base-uncased Model is the best perfoming model. It has the higest accuracy and none of the other models are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b5693",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
